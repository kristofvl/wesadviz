# WESAD vizualization

An in-browser data visualizer for the [WESAD benchmark dataset](https://ubi29.informatik.uni-siegen.de/usi/data_wesad.html) (see [this paper](https://dl.acm.org/doi/10.1145/3242969.3242985) (*) for details), based on heavy compression of all data into a javascript-friendly format and using the [uplot library](https://github.com/leeoniya/uPlot) for interactive plotting.

Try it out for yourself [by clicking here](https://kristofvl.github.io/wesadviz/)

*: This multimodal dataset features physiological and motion data, recorded from both a wrist- and a chest-worn device, of 15 subjects during a lab study. The following sensor modalities are included: blood volume pulse, electrocardiogram, electrodermal activity, electromyogram, respiration, body temperature, and three-axis acceleration. Moreover, the dataset bridges the gap between previous lab studies on stress and emotions, by containing three different affective states (neutral, stress, amusement). In addition, self-reports of the subjects, which were obtained using several established questionnaires, are contained in the dataset. Details can be found in the dataset's readme-file, as well as in: 

Introducing WESAD, a Multimodal Dataset for Wearable Stress and Affect Detection, Philip Schmidt and Attila Reiss and Robert Duerichen and Claus Marberger and Kristof Van Laerhoven, In 20th ACM International Conference on Multimodal Interaction (ICMI â€™18), 2018. [[pdf](https://kristofvl.github.io/usi/pdf/ubi_icmi2018.pdf)][[scholar](https://scholar.google.com/scholar?as_q=Introducing%20WESAD,%20a%20Multimodal%20Dataset%20for%20Wearable%20Stress%20and%20Affect%20Detection)][[bibtex](https://api.crossref.org/works/10.1145/3242969.3242985/transform/application/x-bibtex)]

The dataset is available at [https://ubi29.informatik.uni-siegen.de/usi/data_wesad.html](https://ubi29.informatik.uni-siegen.de/usi/data_wesad.html).
